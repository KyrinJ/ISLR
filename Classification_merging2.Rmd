---
title: "Project"
author: "Guanghua Qiao"
date: "2020.6.13"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#load('D:/SJTU Lessons/GSE137140.Rdata')
# pd: clinical
# exp
load("D:/SJTU Lessons/Rawdata1.Rdata")
# Cancerexp,Noncancerexp,Cancer,Noncancer
can=cbind(Cancer,t(Cancerexp))
noncan=cbind(Noncancer,t(Noncancerexp))
table(can$stage)
table(can$type)
# Groups need to be merged
x=can[,-c(1,4:8)]
y=noncan[,-c(1:3)]
y$stage='0'
y$type='0'
# merging & deleting
x1=x[-which(x$stage=='IV'),]
x2=x1
x2$stage[which(x1$stage %in% c('IIIA','IIIB'))]='III'
x2$stage[which(x1$stage %in% c('IIA','IIB'))]='II'
x2$stage[which(x1$stage %in% c('IA','IB'))]='I'
# age & sex
str(y$Age)
y1=y
for (i in 1:dim(y1)[1]){
  y1$Age[i]=as.numeric(unlist(strsplit(y$Age[i],split=': '))[2])
}
y2=na.omit(y1)
y2$Age=as.numeric(y2$Age)
y3=y2[-which(y2$Age==7),]
x3=x2
for (i in 1:dim(x2)[1]){
  x3$Age[i]=as.numeric(unlist(strsplit(x2$Age[i],split=': '))[2])
}
x3$Age=as.numeric(x3$Age)

rawcombine=rbind(x3,y3)
str(rawcombine$Age)

table(x3$Sex)
summary(x3$Age)
summary(y3$Age)
ggplot(rbind(x3,y3), aes(x=stage,y=Age))+geom_boxplot()

######  seperate train & test set  ######
# extract train set directly
age.size=c(sum(y3$Age<30),
sum(y3$Age>=30 & y3$Age<40),
sum(y3$Age>=40 & y3$Age<50),
sum(y3$Age>=50 & y3$Age<60),
sum(y3$Age>=60 & y3$Age<70),
sum(y3$Age>=70 & y3$Age<80),
sum(y3$Age>=80))
strata.size=age.size*100/2176
strata.size2=c(1,18,28,30,17,5,1)
y.str=y3
for (i in 1:dim(y.str)[1]){
  if (y.str$Age[i]<30) {
    y.str$AgeGroup[i]='age20s'
  } else if (y.str$Age[i]<40){
    y.str$AgeGroup[i]='age30s'
  } else if (y.str$Age[i]<50){
    y.str$AgeGroup[i]='age40s'
  } else if (y.str$Age[i]<60){
    y.str$AgeGroup[i]='age50s'
  } else if (y.str$Age[i]<70){
    y.str$AgeGroup[i]='age60s'
  } else if (y.str$Age[i]<80){
    y.str$AgeGroup[i]='age70s'
  } else{
    y.str$AgeGroup[i]='age80s'
  }
}
y.str$AgeGroup=as.factor(y.str$AgeGroup)
y.str=y.str[order(y.str$AgeGroup),]
library(sampling)
set.seed(11)
strata.train=strata(y.str,stratanames=("AgeGroup"),size=strata.size2,method="srswor")
noncan.train=y.str[strata.train$ID_unit,]


x.str=x3
for (i in 1:dim(x.str)[1]){
  if (x.str$Age[i]<40) {
    x.str$AgeGroup[i]='age30s'
  } else if (x.str$Age[i]<50){
    x.str$AgeGroup[i]='age40s'
  } else if (x.str$Age[i]<60){
    x.str$AgeGroup[i]='age50s'
  } else if (x.str$Age[i]<70){
    x.str$AgeGroup[i]='age60s'
  } else if (x.str$Age[i]<80){
    x.str$AgeGroup[i]='age70s'
  } else{
    x.str$AgeGroup[i]='age80s'
  }
}
x.str$AgeGroup=as.factor(x.str$AgeGroup)
x.str=x.str[order(x.str$stage,x.str$AgeGroup),]
(strata.size_1=table(x.str$stage,x.str$AgeGroup)[1,]*100/971)
(strata.size_2=table(x.str$stage,x.str$AgeGroup)[2,]*100/207)
(strata.size_3=table(x.str$stage,x.str$AgeGroup)[3,]*100/170)
# 3*6=18
strata.size3=c(1,5,17,32,39,6,2,5,12,40,32,9,2,11,15,38,29,5)

set.seed(11)
strata.train2=strata(x.str,stratanames=c("stage","AgeGroup"),size=strata.size3,method="srswor")
can.train=x.str[strata.train2$ID_unit,]



#set.seed(114)
#train.can=sample(1348,1348/2)
#train.noncan=sample(1000,1000/2)
#can.train=x3[train.can,]
#noncan.train=y3[train.noncan,]

table(can.train$stage)
train=rbind(can.train,noncan.train)
test.all=rbind(y.str[-strata.train$ID_unit,],x.str[-strata.train2$ID_unit,])
train$stage=as.factor(train$stage)
test.all$stage=as.factor(test.all$stage)
train=train[,-dim(train)[2]]
test.all=test.all[,-dim(test.all)[2]]
test.all=test.all[,-dim(test.all)[2]]

ggplot(train, aes(x=stage,y=Age))+geom_boxplot()
ggplot(test.all, aes(x=stage,y=Age))+geom_boxplot()
table(test.all$stage)

######  pre-process  ######
summary(train$`hsa-let-7a-5p`)

# normalization?
library(ggplot2)
library(tidyr)
library(reshape2)
mydata<-melt(train[,1:54],                       
       variable.name="miRNA",         
       value.name="value"          
       )
ggplot(mydata, aes(x=miRNA,y=value))+geom_boxplot()



######  LDA & QDA  ######
library(MASS)
lda.fit = lda(stage ~ ., data=train[,-c(2:4)])
#lda.fit
#plot(lda.fit)
#names(lda.fit)
lda.pred = predict(lda.fit, test.all)
table(lda.pred$class, test.all$stage)
mean(lda.pred$class == test.all$stage)

qda.fit = qda(stage ~ ., data=train[,-c(2:4)])
qda.fit
qda.pred = predict(qda.fit, test)
table(qda.pred$class, test$stage)
mean(qda.pred$class == test$stage)


######  KNN  ######
library(class)
library(pROC)
train.X = as.matrix(train[,-c(1:4)])
test.X = as.matrix(test[,-c(1:4)])
set.seed(1)
knn.pred = knn(train.X, test.X, train$stage, k=9)
table(knn.pred, test$stage)
mean(knn.pred == test$stage)
roc=multiclass.roc(ordered(test$stage),ordered(knn.pred))
#str(knn.pred)
#str(ordered(knn.pred))

correct.rate=0
correctrate=rep(NA,50)
auc=rep(NA,50)
## may add macro-ave in this 
for (i in 1:50){
  set.seed(1)
  knn.pred = knn(train.X, test.X, train$stage, k=i)
  roc=multiclass.roc(ordered(test$stage),ordered(knn.pred))
  if (mean(knn.pred == test$stage)>correct.rate) {
    correct.rate=mean(knn.pred == test$stage)
    k <<- i
  }
  correctrate[i]=correct.rate
  auc[i]=roc$auc
}
correct.rate
k
#correct.rate=0.6961,k=92
# k=92 is not suitable
# maybe conclude that KNN perform badly, predicting only categories of 0 & IA (for KNN not suitable for high-D data).
# k=50 only predicts 0, IA & IB

plot(1:50,correctrate,type='l',col='green',xlab='K',ylab='Correct rate & AUC')
lines(1:50,auc,col='red')
legend("bottomright", c('Correct rate', "AUC"), col=c("green", "red"), cex=1, lty=1)

max(auc)
which(auc==max(auc))


######  tree  ######
library(MASS)
library(tree)
library(randomForest)

train.tree <- train[,-c(2:4)]
colnames(train.tree)=c("stage", paste0("miRNA", 1:641))
test.tree <- test.all[,-c(1:2)]
colnames(test.tree)=c(paste0("miRNA", 1:641),"stage")
#train.tree$stage=as.factor(train.tree$stage)
#test.tree$stage=as.factor(test.tree$stage)

set.seed(98)
tree.Cancer = tree(stage ~ .,train.tree)
summary(tree.Cancer)
tree.Cancer
plot(tree.Cancer)
text(tree.Cancer, pretty = 0)
pred = predict(tree.Cancer, test.tree, type = "class")
table(pred,test.tree$stage)

cv.Cancer= cv.tree(tree.Cancer, FUN = prune.misclass)
cv.Cancer= cv.tree(tree.Cancer, FUN = prune.tree)
cv.Cancer
plot(cv.Cancer$size, cv.Cancer$dev, type = "b", xlab = "Tree Size", ylab = "Deviance")
msize = cv.Cancer$size[which.min(cv.Cancer$dev)]
Cancer.pruned = prune.tree(tree.Cancer, best = msize)
Cancer.pruned
summary(Cancer.pruned)
plot(Cancer.pruned)
text(Cancer.pruned, pretty=0)

misclass.unpruned = sum(test.tree$stage != pred)
misclass.unpruned / length(pred)
pred.pruned = predict(Cancer.pruned, test, type = "class")
misclass.pruned = sum(test.tree$stage != pred.pruned)
misclass.pruned / length(pred.pruned)

# Random Forest
X.train = train.tree[,-1]
X.test = test.tree[,-1]
Y.train = train.tree[,1]
Y.test = test.tree[,1]
p = dim(train.tree)[2] - 1
p.2 = p / 2
p.sq = sqrt(p)
set.seed(11)
rf.p = randomForest(X.train, Y.train, xtest=X.test, ytest=Y.test, mtry=p, ntree=500)
rf.p.2 = randomForest(X.train, Y.train, xtest=X.test, ytest=Y.test, mtry=p.2, ntree=500)
rf.p.sq = randomForest(X.train, Y.train, xtest=X.test, ytest=Y.test, mtry=p.sq, ntree=500)
plot(1:500, rf.p$test$err.rate[,1], col="green", type="l", xlab="Number of Trees", ylab="Test MSE")
lines(1:500, rf.p.2$test$err.rate[,1], col="red", type="l")
lines(1:500, rf.p.sq$test$err.rate[,1], col="blue", type="l")
legend("topright", c("m=p", "m=p/2", "m=sqrt(p)"), col=c("green", "red", "blue"), cex=1, lty=1)

table(rf.p.sq$predicted,test.tree$stage)
mean(rf.p.sq$predicted == test.tree$stage)

# Boosting
library(gbm)
set.seed(342)
boost.Cancer = gbm(stage~., data=train.tree, n.trees=1000, shrinkage=0.01)
summary(boost.Cancer)
boost.prob = predict(boost.Cancer,test.tree, n.trees=1000, type="response")
#boost.pred = ifelse(boost.prob >0.5, 1, 0)
stage.pred=rep(NA,dim(boost.prob)[1])
for (i in 1:dim(boost.prob)[1]){
  for (j in 1:dim(boost.prob)[2]){
    if (boost.prob[i,j,1]==max(boost.prob[i,,1])){
      stage.pred[i]=colnames(boost.prob)[j]
    }
  }
}
stage.pred=as.factor(stage.pred)
table(stage.pred,test.tree$stage)
mean(stage.pred == test.tree$stage)

# calculate macro-average for boosting model
confu=as.matrix(table(stage.pred,test.tree$stage))
macro.ave=function(confusion.matrix,test=2){
  p=dim(confusion.matrix)[2]
  if (test==2){
    y=rep(NA,p)
    for (i in 1:p){
      y[i]=confusion.matrix[i,i]/sum(confusion.matrix[,i])
    }
    return(mean(y))
  } else if (test==1){
    y=rep(NA,p)
    for (i in 1:p){
      y[i]=confusion.matrix[i,i]/sum(confusion.matrix[i,])
    }
    return(mean(y))
  }
}
macro.ave(confu)
macro.ave(as.matrix(table(lda.pred$class, test.all$stage)))
macro.ave(as.matrix(table(knn.pred, test$stage)))
macro.ave(as.matrix(table(pred,test.tree$stage)))
macro.ave(as.matrix(table(rf.p.sq$predicted,test.tree$stage)))
macro.ave(as.matrix(table(rf.p.2$predicted,test.tree$stage)))




######  type  ######
table(can$type)
sclc=x[which(x$type %in% c('adenocarcinoma','adenosquamous carcinoma','large cell carcinoma','squamous cell carcinoma','small cell carcinoma')),]
#dim(sclc)==c(1293,645)
table(sclc$type)
set.seed(100)
train.sclc=sample(1293,647)
sclc.train=sclc[train.sclc,]
sclc.test=sclc[-train.sclc,]

lda.fit=lda(type~.,data=sclc.train[,-c(1,3,4)])
lda.pred=predict(lda.fit,sclc.test)
table(lda.pred$class, sclc.test$type)
mean(lda.pred$class==sclc.test$type)
# correct rate=0.1347 hhhhhh lol

sclc2=sclc
sclc2$type[which(sclc$type != 'small cell carcinoma')]='NSCLC'
# try different seeds for convenien lazy..
set.seed(11459)
train.sclc2=sample(1293,647)
sclc.train=sclc2[train.sclc2,]
sclc.test=sclc2[-train.sclc2,]
table(sclc.train$type)

lda.fit=lda(type~.,data=sclc.train[,-c(1,3,4)])
lda.pred=predict(lda.fit,sclc.test)
table(lda.pred$class, sclc.test$type)
mean(lda.pred$class==sclc.test$type)
# micro-ave=0.71  macro-ave=0.49
# if predict all as NSCLC:
# micro-ave=0.99  macro-ave=0.5

```





